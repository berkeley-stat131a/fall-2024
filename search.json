[
  {
    "objectID": "assignment3.html",
    "href": "assignment3.html",
    "title": "üìù HW3",
    "section": "",
    "text": "Due date: Friday, October 18 Sunday, October 20 at midnight.\n‚è≥ We recommend reading through each problem ASAP so you can accurately estimate the time needed to complete the assignment.\nUnless otherwise stated, assignments in STAT 131A are to be done individually.\nSome components of this assignment have not been seen by a previous cohort of STAT 131A students, so there may be some unforeseen hiccups."
  },
  {
    "objectID": "assignment3.html#submission",
    "href": "assignment3.html#submission",
    "title": "üìù HW3",
    "section": "üìÆ Submission",
    "text": "üìÆ Submission\nSubmit your assignment via Gradescope. The Gradescope will be live at least a few days before the HW deadline.\n\nMake sure to tag your answers properly on Gradescope, or else you may be docked points for making the grading process more time-consuming.\n\nYou must submit a PDF of any PingPong chats that include code you used in your submission.\n\nThis should take the form of one long PDF. One way to do this is to copy all of your relevant PingPong chats into a Google Doc, and then print the doc as a PDF.\nYou are responsible for understanding all the code you submit, regardless of whether or not you used PingPong for help.\n\nFor the coding component, you will produce both (1) a .Rmd file with your code and (2) an PDF file containing the code and output.\n\nOn Gradescope, you will submit a single ZIP file containing both the .Rmd and PDF files.\nTo generate a PDF of your code and output, do not knit to PDF. Instead, knit your .Rmd file as HTML, open the HTML file in a web browser, and then print the HTML as a PDF, making sure that none of your code or output is cut off. You can generate an HTML file in RStudio by pressing Knit and then Knit to HTML.\nThe knitting process will not work if there are errors in your code, so be sure to leave plenty of time to knit your lab notebooks before the deadline.\nProofread your PDF to make sure all of your answers and plots are visible. If your PDF file is really long, it is possible that your code is printing out a large dataset or a really long vector. Make sure to comment out any code that prints more information than each question asks you for.\n\nFor math problems, prepare a photo of your handwritten answers to each problem, convert the photo to a PDF, and submit the PDF to Gradescope.\n\nAlternatively, you can use \\(\\LaTeX\\) to typeset your answers within a .Rmd file within RStudio, or using another \\(\\LaTeX\\) editor like Overleaf.\nThe basics of \\(\\LaTeX\\) are useful to learn if you ever plan to include a mathematical expression in a presentation or document in the future.\nHere‚Äôs a nice guide for getting started.\nWe can also help with \\(\\LaTeX\\) in office hours or via Ed."
  },
  {
    "objectID": "assignment3.html#blood-glucose-the-bootstrap-and-simple-linear-regression-with-r-50-of-the-hw3-grade",
    "href": "assignment3.html#blood-glucose-the-bootstrap-and-simple-linear-regression-with-r-50-of-the-hw3-grade",
    "title": "üìù HW3",
    "section": "ü©∏ Blood glucose, the bootstrap, and simple linear regression with R (50% of the HW3 grade)",
    "text": "ü©∏ Blood glucose, the bootstrap, and simple linear regression with R (50% of the HW3 grade)\nDataHub\n\nThe HW3 coding problems are located in 131a-labs-fall-2024 directory.\n\nGitHub\n\nThe coding problems build on the concepts covered in Labs 4a, 4b, and 5, so be sure to review all three labs before attempting the coding questions.\n\nWhy answer this problem? Lecture has emphasized that the bootstrap can be used to estimate standard errors for a wide variety of estimators. This problem links the bootstrap to the next major topic in 131A: regression."
  },
  {
    "objectID": "assignment3.html#experiment-design-50-of-the-hw3-grade",
    "href": "assignment3.html#experiment-design-50-of-the-hw3-grade",
    "title": "üìù HW3",
    "section": "ü•º Experiment design (50% of the HW3 grade)",
    "text": "ü•º Experiment design (50% of the HW3 grade)\nWhy answer this problem? This question synthesizes all of the material covered in Lectures 4 through 12b. If you come out of 131A with a solid understanding of the framework behind this question, you will be well-prepared to perform basic statistical inference in the real world, and also primed to learn new inference methods on the fly.\nStatins are drugs that reduce LDL (‚Äúbad cholesterol‚Äù) levels.\n\nHigh LDL levels are associated with an increased risk of adverse health outcomes, such as heart attacks and strokes.\nAbout 15% of the U.S. population is on some form of statin.\n\n\nFun fact: Early in COVID, Josh was eating so much chicken curry that his LDL went to unusually high levels for his age. As it turns out, one can of coconut milk has about 68 grams of saturated fat, which is a major contributor to LDL levels. Josh was eating the equivalent of two cans of coconut milk every week. By changing his diet, Josh was able to avoid needing a statin to manage his LDL levels. However, keep in mind that LDL levels are not just a function of diet, but also genetics, exercise, and other factors.\n\nFor the problem below, please show all steps.\n\nYou are welcome to use a scientific calculator or R for arithmetic (e.g., no need to do long division by hand).\n\nSuppose UC Berkeley scientists develop a new LDL-reducing drug.\n\nThe scientists want to compare the average efficacy of the new drug to the average efficacy of a brand name statin called Lipitor.\nThe scientists randomly assign either the new drug or Lipitor to 80 year-old patients with similarly high LDL levels.\n\nAfter three months of the patients taking either the new drug or Lipitor, you obtain the following data on LDL levels for the patients in each group.\n\nNote that LDL is measured in milligrams of LDL per deciliter of blood (mg/dL), Blood glucose has the same units (see coding section!).\n\n  ldl_lipitor = c(208, 197, 184, 194, 201, 196, 181, 207, 176, 198, 188, 195, 184, 189, 205, 188, 190, 188, 192, 181, 176, 193, 181, 176)\n  \n  ldl_new_drug = c(181, 190, 193, 176, 205, 161, 193, 189, 171, 180, 185, 185, 206, 173, 197, 179, 199, 170, 195, 176, 183, 186, 180, 182, 185, 178, 178)\nFor this scenario, answer the following:\n\nEstimand\n\nWhat is a reasonable difference in means estimand?\n\nMake sure to define any terms used in your estimand, and be specific about the relevant population.\n\n\n\n\nNull hypothesis\n\nWhat is a reasonable null hypothesis that uses your estimand?\n\n\n\nEstimator\n\nWhat is a reasonable estimator for your estimand?\n\nAgain, make sure to define any variables used in your answer.\n\nWhat is your point estimate? Make sure to include units.\nWhat is the sampling distribution of your estimator under the null hypothesis?\n\nHint: Is the normal distribution appropriate given the number of observations?\n\n\n\n\nConfidence interval\n\nWhat is a 90% confidence interval for your estimand?\n\nDerive your answer using &lt;r,p,q,d&gt;&lt;distribution&gt; R functions (e.g., runif).\nConfirm your answer by using a built-in hypothesis testing function in R (e.g., prop.test). You may have to use Google or PingPong to find the right testing function!\nThe derived result and testing function result should be similar, but it is OK if they are slightly different due to subtle differences in underlying methodology.\nThe code notebook for this HW contains space to include your code for question 6.\n\n\n\n\nHypothesis test\n\nWhat is the two-sided p-value associated with your null hypothesis and point estimate?\n\nDerive your answer using &lt;r,p,q,d&gt;&lt;distribution&gt; R functions (e.g., runif).\nConfirm your answer by using a built-in hypothesis testing function in R (e.g., prop.test).\nAgain, the derived result and testing function result should be similar, but it is OK if they are slightly different.\n\nWhat range of point estimates would have rejected the null hypothesis at a significance level (i.e., \\(\\alpha\\)) of 0.1?\nIs the result of your hypothesis test consistent with your confidence interval? Why or why not?\n\nThe code notebook for this HW contains space to include your code for questions 7 through 9.\n\n\n\n\nPower\n\nProvide a reasonable estimate of the power of a hypothesis test with \\(\\alpha=0.1\\) and sample sizes equal to the sample sizes in the data above.\n\nBe sure to state any additional assumptions needed to calculate power.\nDerive your answer using &lt;r,p,q,d&gt;&lt;distribution&gt; R functions (e.g., runif).\nConfirm your answer using an online power calculator. Take a screenshot of the calculator‚Äôs output as confirmation, and submit this screenshot with your handwritten work. There are many power calculators available. Google is your friend here!\nThe derived power and power calculator output should be similar, but it is OK if they are slightly different.\nThe code notebook for this HW contains space to include your code for question 10.\n\n\n\nIn general, power should be calculated BEFORE a hypothesis test, not after. Calculating power after an experiment is considered ‚Äúcheating.‚Äù At the end of the day, this problem is simply intended to give you some practice calculating power. See this blog post for more details. Post-hoc (i.e., after the fact) power calculations are bad practice, but very common!\n\n\nAlso, we typically calculate power for a range of possible effect sizes, sample sizes, and significance levels (\\(\\alpha\\)), and generate power curves that are functions of these inputs. With some massaging, you could optionally turn your code for question 10 into a function that takes effect size, sample size, and significance levels as inputs, and returns power. Then, you could use geom_function to draw a power curve. It‚Äôs less code than you might think! See the Lecture 12 code for boilerplate power curve code."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Due dates",
    "section": "",
    "text": "DataHub\nGitHub\nDue date: Monday, September 9, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-1",
    "href": "assignments.html#lab-1",
    "title": "Due dates",
    "section": "",
    "text": "DataHub\nGitHub\nDue date: Monday, September 9, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw1",
    "href": "assignments.html#hw1",
    "title": "Due dates",
    "section": "HW1 üìä",
    "text": "HW1 üìä\nHW 1 details\nDue date: Friday, September 13, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-2",
    "href": "assignments.html#lab-2",
    "title": "Due dates",
    "section": "Lab 2 üîî",
    "text": "Lab 2 üîî\nDataHub\nGitHub\nDue date: Wednesday, September 18, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-3",
    "href": "assignments.html#lab-3",
    "title": "Due dates",
    "section": "Lab 3 üë•",
    "text": "Lab 3 üë•\nDataHub\nGitHub\nYour Lab 3 submission must include a completed PDF of the Lecture 8 worksheet.\n\nYou can ignore the two normal distribution plots at the end of the worksheet.\n\nDue date: Monday, September 23, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw2",
    "href": "assignments.html#hw2",
    "title": "Due dates",
    "section": "HW2 üç¨",
    "text": "HW2 üç¨\nHW 2 details\nDue date: Friday, September 27 Monday, September 30, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-4-part-a-and-part-b",
    "href": "assignments.html#lab-4-part-a-and-part-b",
    "title": "Due dates",
    "section": "Lab 4 (Part A and Part B) ü©∏",
    "text": "Lab 4 (Part A and Part B) ü©∏\nDataHub (Part A and B)\nGitHub (Part A and B)\nDue date: Wednesday, October 2, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#midterm-1",
    "href": "assignments.html#midterm-1",
    "title": "Due dates",
    "section": "Midterm 1 üìù",
    "text": "Midterm 1 üìù\nWednesday, October 9, 2-3pm in Morgan 101",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-5",
    "href": "assignments.html#lab-5",
    "title": "Due dates",
    "section": "Lab 5 ü•æ",
    "text": "Lab 5 ü•æ\nLab 5 (DataHub)\nLab 5 (GitHub)\nDue date: Friday, October 11, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw3",
    "href": "assignments.html#hw3",
    "title": "Due dates",
    "section": "HW3 üß™",
    "text": "HW3 üß™\nHW 3 details\nDue date: Friday, October 18 Sunday, October 20, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-6",
    "href": "assignments.html#lab-6",
    "title": "Due dates",
    "section": "Lab 6",
    "text": "Lab 6\nLab 6 (DataHub)\nLab 6 (GitHub)\nDue date: Wednesday, October 23, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-7-parts-a-and-b-part-a",
    "href": "assignments.html#lab-7-parts-a-and-b-part-a",
    "title": "Due dates",
    "section": "Lab 7, Parts A and B Part A",
    "text": "Lab 7, Parts A and B Part A\nLab 7 (DataHub)\nLab 7 (GitHub)\nPart B posted shortly after Part A. There is no longer a Part B to Lab 7.\nDue date: Monday, October 28, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-8",
    "href": "assignments.html#lab-8",
    "title": "Due dates",
    "section": "Lab 8",
    "text": "Lab 8\nLink forthcoming.\nDue date: Friday, November 8, midnight PT\nNote: This due date should have been Friday, November 1. I‚Äôm leaving the deadline as 11/8 to minimize confusion, but note that HW4 draws on material from Lab 8.",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw4",
    "href": "assignments.html#hw4",
    "title": "Due dates",
    "section": "HW4",
    "text": "HW4\nHW 4 details\nDue date: Monday, November 4, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-9",
    "href": "assignments.html#lab-9",
    "title": "Due dates",
    "section": "Lab 9",
    "text": "Lab 9\nLink forthcoming.\nDue date: Friday, November 8, midnight PT\nNote: Lab 8 is also due on 11/8. See above.",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#midterm-2",
    "href": "assignments.html#midterm-2",
    "title": "Due dates",
    "section": "Midterm 2",
    "text": "Midterm 2\nWednesday, November 13, 2-3pm in Morgan 101",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-10",
    "href": "assignments.html#lab-10",
    "title": "Due dates",
    "section": "Lab 10",
    "text": "Lab 10\nLink forthcoming.\nAnticipated due date: Friday, November 22, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw5",
    "href": "assignments.html#hw5",
    "title": "Due dates",
    "section": "HW5",
    "text": "HW5\nDetails forthcoming.\nAnticipated due date: Monday, November 25, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#lab-11",
    "href": "assignments.html#lab-11",
    "title": "Due dates",
    "section": "Lab 11",
    "text": "Lab 11\nLink forthcoming.\nAnticipated due date: Friday, December 6, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#hw6",
    "href": "assignments.html#hw6",
    "title": "Due dates",
    "section": "HW6",
    "text": "HW6\nDetails forthcoming.\nAnticipated due date: Monday, December 9, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#final-project",
    "href": "assignments.html#final-project",
    "title": "Due dates",
    "section": "Final project",
    "text": "Final project\nDetails forthcoming.\nAnticipated due date: Sunday, December 15, midnight PT",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "assignments.html#final-exam",
    "href": "assignments.html#final-exam",
    "title": "Due dates",
    "section": "Final exam",
    "text": "Final exam\nThursday, December 19, 3-6pm @ TBD Location",
    "crumbs": [
      "HW, Labs, Project"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "assignment4.html",
    "href": "assignment4.html",
    "title": "üìù HW4",
    "section": "",
    "text": "Due date: Monday, November 4 at midnight.\n‚è≥ We recommend reading through each problem ASAP so you can accurately estimate the time needed to complete the assignment.\nUnless otherwise stated, assignments in STAT 131A are to be done individually.\nSome components of this assignment have not been seen by a previous cohort of STAT 131A students, so there may be some unforeseen hiccups."
  },
  {
    "objectID": "assignment4.html#submission",
    "href": "assignment4.html#submission",
    "title": "üìù HW4",
    "section": "üìÆ Submission",
    "text": "üìÆ Submission\nSubmit your assignment via Gradescope. The Gradescope will be live at least a few days before the HW deadline.\n\nMake sure to tag your answers properly on Gradescope, or else you may be docked points for making the grading process more time-consuming.\n\nYou must submit a PDF of any PingPong chats that include code you used in your submission.\n\nThis should take the form of one long PDF. One way to do this is to copy all of your relevant PingPong chats into a Google Doc, and then print the doc as a PDF.\nYou are responsible for understanding all the code you submit, regardless of whether or not you used PingPong for help.\n\nFor the coding component, you will produce both (1) a .Rmd file with your code and (2) an PDF file containing the code and output.\n\nOn Gradescope, you will submit a single ZIP file containing both the .Rmd and PDF files.\nTo generate a PDF of your code and output, do not knit to PDF. Instead, knit your .Rmd file as HTML, open the HTML file in a web browser, and then print the HTML as a PDF, making sure that none of your code or output is cut off. You can generate an HTML file in RStudio by pressing Knit and then Knit to HTML.\nThe knitting process will not work if there are errors in your code, so be sure to leave plenty of time to knit your lab notebooks before the deadline.\nProofread your PDF to make sure all of your answers and plots are visible. If your PDF file is really long, it is possible that your code is printing out a large dataset or a really long vector. Make sure to comment out any code that prints more information than each question asks you for."
  },
  {
    "objectID": "assignment4.html#forms-to-complete-0-of-the-hw2-grade",
    "href": "assignment4.html#forms-to-complete-0-of-the-hw2-grade",
    "title": "üìù HW4",
    "section": "üìù Forms to complete (0% of the HW2 grade)",
    "text": "üìù Forms to complete (0% of the HW2 grade)\nIf you have not already, complete the follow-up anonymous course pulse check.\n\nTo make sure everyone‚Äôs opinion is represented in any subsequent changes to the course, is critical to get 100% participation on this survey.\nAs the saying goes, ‚ÄúThe squeaky wheel gets the grease.‚Äù"
  },
  {
    "objectID": "assignment4.html#inference-and-prediction-with-multiple-regression-in-r-100-of-the-hw4-grade",
    "href": "assignment4.html#inference-and-prediction-with-multiple-regression-in-r-100-of-the-hw4-grade",
    "title": "üìù HW4",
    "section": "üîÆ Inference and prediction with multiple regression in R (100% of the HW4 grade)",
    "text": "üîÆ Inference and prediction with multiple regression in R (100% of the HW4 grade)\nDataHub\n\nThe HW4 coding problems are located in 131a-labs-fall-2024 directory.\n\nGitHub"
  },
  {
    "objectID": "assignment2.html",
    "href": "assignment2.html",
    "title": "üìù HW2",
    "section": "",
    "text": "Due date: Friday, September 27 Monday, September 30 at midnight.\n‚è≥ We recommend reading through each problem ASAP so you can accurately estimate the time needed to complete the assignment.\nUnless otherwise stated, assignments in STAT 131A are to be done individually.\nSome components of this assignment have not been seen by a previous cohort of STAT 131A students, so there may be some unforeseen hiccups."
  },
  {
    "objectID": "assignment2.html#submission",
    "href": "assignment2.html#submission",
    "title": "üìù HW2",
    "section": "üìÆ Submission",
    "text": "üìÆ Submission\nSubmit your assignment via Gradescope. The Gradescope will be live at least a few days before the HW deadline.\n\nMake sure to tag your answers properly on Gradescope, or else you may be docked points for making the grading process more time-consuming.\n\nYou must submit a PDF of any PingPong chats that include code you used in your submission.\n\nThis should take the form of one long PDF. One way to do this is to copy all of your relevant PingPong chats into a Google Doc, and then print the doc as a PDF.\nYou are responsible for understanding all the code you submit, regardless of whether or not you used PingPong for help.\n\nLike HW1, you will submit your screencast feedback in two places: (1) Gradescope and (2) Google Forms.\nGoogle Form for submitting feedback\nFor coding components, you will produce both (1) a .Rmd file with your code and (2) an PDF file containing the code and output.\n\nOn Gradescope, you will submit a single ZIP file containing both the .Rmd and PDF files.\nTo generate a PDF of your code and output, do not knit to PDF. Instead, knit your .Rmd file as HTML, open the HTML file in a web browser, and then print the HTML as a PDF, making sure that none of your code or output is cut off. You can generate an HTML file in RStudio by pressing Knit and then Knit to HTML.\nThe knitting process will not work if there are errors in your code, so be sure to leave plenty of time to knit your lab notebooks before the deadline.\nProofread your PDF to make sure all of your answers and plots are visible. If your PDF file is really long, it is possible that your code is printing out a large dataset or a really long vector. Make sure to comment out any code that prints more information than each question asks you for.\n\nFor math problems, prepare a photo of your handwritten answers to each problem, convert the photo to a PDF, and submit the PDF to Gradescope.\n\nAlternatively, you can use \\(\\LaTeX\\) to typeset your answers within a .Rmd file within RStudio, or using another \\(\\LaTeX\\) editor like Overleaf.\nThe basics of \\(\\LaTeX\\) are useful to learn if you ever plan to include a mathematical expression in a presentation or document in the future.\nHere‚Äôs a nice guide for getting started.\nWe can also help with \\(\\LaTeX\\) in office hours or via Ed."
  },
  {
    "objectID": "assignment2.html#forms-to-complete-0-of-the-hw2-grade",
    "href": "assignment2.html#forms-to-complete-0-of-the-hw2-grade",
    "title": "üìù HW2",
    "section": "üìù Forms to complete (0% of the HW2 grade)",
    "text": "üìù Forms to complete (0% of the HW2 grade)\nIf you have not already, complete the anonymous course pulse check.\n\nTo make sure everyone‚Äôs opinion is represented in any subsequent changes to the course, is critical to get 100% participation on this survey.\nAs the saying goes, ‚ÄúThe squeaky wheel gets the grease.‚Äù"
  },
  {
    "objectID": "assignment2.html#plot-presentation-feedback-10-20",
    "href": "assignment2.html#plot-presentation-feedback-10-20",
    "title": "üìù HW2",
    "section": "üó£Ô∏è Plot presentation feedback (10%) (20%)",
    "text": "üó£Ô∏è Plot presentation feedback (10%) (20%)\nYou will be emailed a screencast ID for another student‚Äôs screencast from HW1.\n\nIf you have not received an email with a link by Thursday, September 19th at midnight, please open a private Ed post.\nIf you did not submit a screencast for HW1, you will not receive an email with an assigned screencast ID. If you would like to review a screencast for HW2, please open a private Ed post letting us know.\nPublic links to screencasts can be found here.\n\nFor this exercise, you will write detailed feedback on your assigned screencast.\n\nKeep in mind that this feedback will be anonymously provided to the student who recorded the screencast.\nPlease be constructive and supportive with any criticism, and do not hold back on providing praise where deserved!\n\nAs you write your feedback, you may want to consider the prompts below. However, do not feel limited to just these prompts, and do not feel compelled to address every single prompt.\n\nWhat did you enjoy most about the presentation?\nWhat insights did you find particularly interesting?\nDid the presenter follow the key three tips of describing the x-axis, describing the y-axis, and explaining a plot feature (e.g., a point or line) in context, before diving into the details?\nCould the presenter have done anything to help you understand the plot more easily? Were you confused at any point?\nDid you find the tone of the presentation engaging? Did it sound like the presenter had practiced their presentation, or that they spent time thoughtfully writing a script for the presentation?\nDid the presenter sufficiently describe the contents of the plot?\nDid you have enough background information to understand the plot? Could the presentation have benefited from any more background information?\nDid the presenter describe the key takeaways of the plot? In other words, did the presenter explain why the plot actually matters in a real life context, as opposed to just explain how to read the plot?\nDid the presenter provide any extraneous information or ‚Äúover-describe‚Äù anything? In other words, could the presenter have shortened any parts of the presentation without harming its key takeaways?\nWould any parts of the presentation benefit from more description or detail? Did anything feel rushed? \nDo you have any ‚Äúnits‚Äù about the presentation (i.e., very small changes that could improve the presentation, like a typo or mispronunciation)? If you choose to answer this prompt, it should not take up more than 10% of the text of your entire feedback. Focus your energy on the ‚Äúbig picture‚Äù prompts.\n\nYour feedback will be graded based on demonstrated effort and thoughtfulness.\n\nYou should aim to write at least two paragraphs of feedback.\nYour feedback can alternatively be written as an organized, bulleted list equivalent in word count to at least two paragraphs.\n\nWhy complete this problem? Writing detailed feedback on another student‚Äôs plot presentation will help you become a better presenter. One of the hardest data science skills to develop is ‚Äúpresentation empathy‚Äù, or a sense of how someone who has never seen your work before will interpret your presentations After staring at your own work for hours, it can be hard to see your work with ‚Äúfresh eyes‚Äù. If you are at all surprised by the feedback you receive on your own screencast (or receive feedback with which you disagree!), take that moment as an excellent opportunity to understand how other people can interpret your work differently than you interpret your own work. Remember, it is not the audience‚Äôs responsibility to decipher your presentation for its intended interpretation. You need to carefully prepare your presentation so that the intended interpretation is crystal clear!"
  },
  {
    "objectID": "assignment2.html#rapid-tests-for-covid-and-bayes-rule-25-30",
    "href": "assignment2.html#rapid-tests-for-covid-and-bayes-rule-25-30",
    "title": "üìù HW2",
    "section": "ü•º Rapid tests for COVID and Bayes‚Äô Rule (25%) (30%)",
    "text": "ü•º Rapid tests for COVID and Bayes‚Äô Rule (25%) (30%)\nFor the problem below, please show all steps. You are welcome to use a scientific calculator for arithmetic (e.g., no need to do long division by hand).\nUsing Bayes‚Äô Rule, estimate the following two quantities for tests sold in Berkeley, California in September 2024:\n\n\\(\\Pr(\\text{COVID} | \\text{Positive Nasal Swab Rapid Test})\\)\n\\(\\Pr(\\text{No COVID} | \\text{Negative Nasal Swab Rapid Test})\\)\n\nEach of the quantities you use in your estimation procedure should be from different sources.\n\nFor example, you might estimate \\(\\Pr(\\text{COVID})\\) from CDC data, and \\(\\Pr(\\text{Positive Nasal Swab Rapid Test} | \\text{COVID})\\) from a manufacturer‚Äôs website.\nBe sure to include a link to the source of each quantity you use in your estimation procedure.\n\nIn order to complete this problem, you will need to make assumptions. Explicitly document every assumption you make, and explain why you think the assumption is or is not reasonable.\n\nFor example, you probably will not have access to data from September 2024.\nSo, you will have to make assumptions about how reasonable your chosen data is for estimating the two quantities above for September 2024.\n\nBe scrappy. You will have to do a substantial amount of Google searching to complete this problem.\n\nYour answer may be very different than other students‚Äô answers, and that‚Äôs okay!\n\nWhy complete this problem? We often do not have perfect data to answer research questions. So, we have to make do with what we can access. This problem is designed to practice the skill of pulling together multiple data sources and documenting assumptions. It will also familiarize you with writing more complex probabilistic expressions."
  },
  {
    "objectID": "assignment2.html#setting-up-spam-classification-with-naive-bayes-15-this-question-is-now-optional-and-worth-up-to-two-points-of-extra-credit.",
    "href": "assignment2.html#setting-up-spam-classification-with-naive-bayes-15-this-question-is-now-optional-and-worth-up-to-two-points-of-extra-credit.",
    "title": "üìù HW2",
    "section": "üì§ Setting up spam classification with Naive Bayes (15%) This question is now optional, and worth up to two points of extra credit.",
    "text": "üì§ Setting up spam classification with Naive Bayes (15%) This question is now optional, and worth up to two points of extra credit.\nIn the coding portion of the homework, you will implement a Naive Bayes classifier to classify emails as spam or not spam. This problem will help kick start your implementation of Naive Bayes in R.\n\nTo prepare for this problem, you may find it helpful to watch this tutorial on Naive Bayes for spam classification.\nYou may also want to read the IRS race classification slides that we did not have time to cover in lecture.\n\n\nExpress the following as a probability statement: ‚ÄúThe probability that an email containing the strings‚Äùfree‚Äù, ‚Äúmoney‚Äù, and ‚Äú$‚Äù is spam.‚Äù\n\nMake sure to define any notation you use in your probability statement.\nFor example, you might define \\(\\Pr(\\text{free})\\) as the probability that an email contains the string ‚Äúfree‚Äù.\n\nUsing Bayes‚Äô Rule, write an equation for your probability statement from part (a).\n\nHint: The right-hand side of the equation should have three distinct terms.\n\nExpand the numerator of the right-hand side of the equation from part (b) using the chain rule of probability.\n\nWe saw the chain rule of probability in lecture: \\(\\Pr(A \\cap B) = \\Pr(A) \\cdot \\Pr(B | A)\\), \\(\\Pr(A \\cap B \\cap C) = \\Pr(A) \\cdot \\Pr(B | A) \\cdot \\Pr(C | A ,B)\\), and so on.\n\nSuppose we make the strong assumption that word occurrences are conditionally independent of the email being spam or not spam.\n\nUnder this assumption, how can we simplify the numerator of the probability statement from part (c)?\n\nDescribe a process for estimating \\(\\Pr(\\text{free} | \\text{spam})\\) using a dataset of emails labeled as spam or not spam.\n\nYour answer to part (d) should contain a term like \\(\\Pr(\\text{free} | \\text{spam})\\), where \\(\\text{free}\\) denotes the event that an email contains the string ‚Äúfree‚Äù and \\(\\text{spam}\\) denotes the event that an email is spam.\n\nFinally, suppose we use the estimation procedure you proposed in part (e) to estimate the terms in the numerator of the right-hand side of your probability statement from part (d).\n\nIf we want to classify an email as more likely to be spam or not spam, why can we ignore the denominator in the right-hand side of your probability statement from part (d)?\nHint: You may find it helpful rewrite the equation in part (d) for the case where we want to estimate the conditional probability that the email is not spam.\n\n\nOnce you complete parts (a) through (f) above, you are ready to implement a Naive Bayes classifier in R!\nWhy complete this problem? This problem is the first classifier you will implement in 131A. We will return to classifiers when we learn about logistic regression and decision trees. Later in the course, you will be able to compare the performance of your Naive Bayes classifier in HW2 to alternative classifiers trained on the same spam dataset."
  },
  {
    "objectID": "assignment2.html#naive-bayes-and-mms-inference-with-r-50-of-the-hw2-grade",
    "href": "assignment2.html#naive-bayes-and-mms-inference-with-r-50-of-the-hw2-grade",
    "title": "üìù HW2",
    "section": "üç¨ Naive Bayes and M&Ms inference with R (50% of the HW2 grade)",
    "text": "üç¨ Naive Bayes and M&Ms inference with R (50% of the HW2 grade)\nDataHub\n\nThe HW1 coding problems are located in 131a-labs-fall-2024 directory.\n\nGitHub\n\nThe coding problems build on the concepts covered in Labs 2 and 3, so be sure to complete both labs before attempting the coding questions.\nDon‚Äôt attempt the Naive Bayes coding problems until you have completed the Naive Bayes setup above. Note: The Naive Bayes coding problem is now optional, and worth up to five points of extra credit."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "[UNDER CONSTRUCTION]\nWe‚Äôll use data from several real world situations in class."
  },
  {
    "objectID": "data.html#data-1",
    "href": "data.html#data-1",
    "title": "Data",
    "section": "Data 1",
    "text": "Data 1"
  },
  {
    "objectID": "data.html#data-2",
    "href": "data.html#data-2",
    "title": "Data",
    "section": "Data 2",
    "text": "Data 2"
  },
  {
    "objectID": "staff.html",
    "href": "staff.html",
    "title": "üçé Staff",
    "section": "",
    "text": "The teaching staff is excited to have you in 131A!\n\n\n\n Instructor: Josh Grossman Please call me ‚ÄúJosh‚Äù! No need for ‚ÄúProfessor‚Äù, ‚ÄúDr.‚Äù, ‚ÄúSir‚Äù, etc.  jdgg at berkeley dot edu    \n\n\n GSI: Van Hovenga vhovenga at berkeley dot edu      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, please use Ed to communicate with the course staff.\nUnless otherwise indicated, email should only be used for private concerns directed to a specific member of the teaching staff.",
    "crumbs": [
      "Staff"
    ]
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "üìù HW1",
    "section": "",
    "text": "Due date: Friday, September 13 at midnight.\n‚è≥ We recommend reading through each problem ASAP so you can accurately estimate the time needed to complete the assignment.\nUnless otherwise stated, assignments in STAT 131A are to be done individually.\nSome components of this assignment have not been seen by a previous cohort of STAT 131A students, so there may be some unforeseen hiccups.\nWe will use this Ed post to track errors and clarifications on HW1."
  },
  {
    "objectID": "assignment1.html#submission",
    "href": "assignment1.html#submission",
    "title": "üìù HW1",
    "section": "üìÆ Submission",
    "text": "üìÆ Submission\nSubmit your assignment via Gradescope. The Gradescope will be live at least a few days before the HW deadline.\n\nMake sure to tag your answers properly on Gradescope, or else you may be docked points for making the grading process more time-consuming.\n\nYou must submit a PDF of any PingPong chats that include code you used in your submission.\n\nThis should take the form of one long PDF. One way to do this is to copy all of your relevant PingPong chats into a Google Doc, and then print the doc as a PDF.\nYou are responsible for understanding all the code you submit, regardless of whether or not you used PingPong for help.\n\nFor coding components, you will produce both (1) a .Rmd file with your code and (2) an HTML file containing the code and output.\n\nOn Gradescope, you will submit a single ZIP file containing both the .Rmd and HTML files.\nYou can generate an HTML file in RStudio by pressing Knit and then Knit to HTML.\nThe knitting process will not work if there are errors in your code, so be sure to leave plenty of time to knit your lab notebooks before the deadline.\nProofread your HTML to make sure all of your answers and plots are visible. If your HTML file is really long, it is possible that your code is printing out a large dataset or a really long vector. Make sure to comment out any code that prints more information than each question asks you for.\n\nFor the plot presentation, there are two submission steps.\n\nFirst, submit a public link to your screencast via Gradescope. We will dock points and/or dock slip days if the link is not publicly accessible during grading. Test your link in an incognito window to ensure it‚Äôs public.\nSecond, submit the same public link to your screencast using this Google Form. This second step prepares us for HW2, when another student will provide anonymous feedback on your screencast.\n\nFor math problems, prepare a photo of your handwritten answers to each problem, convert the photo to a PDF, and submit the PDF to Gradescope.\n\nAlternatively, you can use \\(\\LaTeX\\) to typeset your answers within a .Rmd file within RStudio, or using another \\(\\LaTeX\\) editor like Overleaf.\nThe basics of \\(\\LaTeX\\) are useful to learn if you ever plan to include a mathematical expression in a presentation or document in the future.\nHere‚Äôs a nice guide for getting started.\nWe can also help with \\(\\LaTeX\\) in office hours or via Ed."
  },
  {
    "objectID": "assignment1.html#forms-to-complete-0-of-the-hw1-grade",
    "href": "assignment1.html#forms-to-complete-0-of-the-hw1-grade",
    "title": "üìù HW1",
    "section": "Forms to complete (0% of the HW1 grade)",
    "text": "Forms to complete (0% of the HW1 grade)\nComplete the new student survey.\nComplete the office hour survey."
  },
  {
    "objectID": "assignment1.html#data-manipulation-and-plotting-with-r-50-of-the-hw1-grade",
    "href": "assignment1.html#data-manipulation-and-plotting-with-r-50-of-the-hw1-grade",
    "title": "üìù HW1",
    "section": "üìà Data manipulation and plotting with R (50% of the HW1 grade)",
    "text": "üìà Data manipulation and plotting with R (50% of the HW1 grade)\nComplete the HW1 coding problems: DataHub\n\n\nThe HW1 coding problems are located in 131a-labs-fall-2024 on DataHub.\nThese problems build on the concepts covered in Lab 1, so be sure to complete Lab 1 before attempting these questions."
  },
  {
    "objectID": "assignment1.html#plot-presentation-30",
    "href": "assignment1.html#plot-presentation-30",
    "title": "üìù HW1",
    "section": "üó£Ô∏è Plot presentation (30%)",
    "text": "üó£Ô∏è Plot presentation (30%)\nIn their 2013 research paper titled The Missing ‚ÄúOne-Offs‚Äù: The Hidden Supply of High-Achieving, Low-Income Students, Caroline Hoxby and Chris Avery investigate the behavior of high-achieving low-income applicants to undergraduate programs in the United States.\nHere is Figure 10 of their research paper:\n\nYour task: Record a 60-90 second screencast describing the plot above.\n\nYour audience is a UC Berkeley undergraduate who has not taken a statistics or data science course, and is unfamiliar with the research paper. You do not need to read the research paper in full to understand the plot, but you might find it helpful to reference.\nIn your screencast, you must explain the minimum necessary background required to understand the plot, along with the key takeaway(s) of the plot.\nYour name and face should not be in the screencast. In other words, the plot should take up the entire window of the screencast, with your voice playing in the background. Do not introduce yourself or use any identifying information.\nYou should use your mouse pointer to indicate particular points of interest on the plot. Alternatively, you can verbally direct the viewer to points of interest (e.g., ‚ÄúIn the top right corner, you can see that‚Ä¶‚Äù).\nYou should use an engaging tone that sounds as though you are presenting to a live audience.\nYou are welcome to read off a script that you have written ahead of time, but try not to make it too obvious. In fact, it can be very helpful to write a script for a presentation ahead of time, even if you do not actually read the script when presenting.\nRemember the three key guiding questions you should address before digging into the details: (1) What‚Äôs on the X axis? (2) What‚Äôs on the Y axis? (3) What does a specific point/line/feature on your plot mean in context?\nThere are lots of free tools for recording screencasts. For example, QuickTime is a useful tool for recording screencasts on a Mac. Feel free to post on Ed if you cannot identify a way to record a screencast anonymously.\nIf you need more than 60-90 seconds to record for accessibility reasons, please let the teaching staff know via Ed.\n\nAs part of HW2, you will provide anonymous feedback on another student‚Äôs submission for this problem.\n\nYour screencast, along with the quality of feedback you provide to another student, will be graded by the teaching staff. At no point will other students grade your work.\n\nüíæ Upload your screencast to your UC Berkeley Google Drive account, or another place that allows you to share a public link.\n\nYou will submit a public link to your screencast in two places. See submission details at the top of this page.\nBefore submitting, make sure your screencast is publicly accessible with the link. One easy way to do this: Open the link in an incognito window in Google Chrome.\nIf your video is private or unviewable when we try to access it, we will not be able to confirm that you submitted your video before the HW1 deadline. You may lose points and/or have to use slip day(s).\n\nWhy complete this problem? Communication is a critical, but often under-appreciated, component of the data science life cycle. This exercise helps develop your data storytelling ability, which is essential for getting anyone to actually care about your statistical analyses!"
  },
  {
    "objectID": "assignment1.html#working-with-probability-density-functions-pdfs-20",
    "href": "assignment1.html#working-with-probability-density-functions-pdfs-20",
    "title": "üìù HW1",
    "section": "üîî Working with probability density functions (PDFs) (20%)",
    "text": "üîî Working with probability density functions (PDFs) (20%)\nFor the problem below, please show all steps. You are welcome to use a scientific calculator for arithmetic (e.g., no need to do long division by hand).\nConsider the function \\(f\\) defined on the interval \\([0,1]\\) : \\(f(x) = cx^\\frac{1}{3}\\).\n\nFind the value of \\(c\\) that makes \\(f\\) a valid PDF for an r.v. \\(X\\).\nWhat is \\(\\Pr(0.1\\leq X \\leq 0.5)\\)?\nWhat is \\(\\Pr(0 \\leq X \\leq x)\\), for any \\(x\\) in \\((0,1)\\)?\nWhat is \\(\\frac{d}{dx} \\Pr(0\\leq X \\leq x)\\)? How does your answer to this problem compare to your answer in the first problem?\nWhat is \\(\\mathbb{E}(X)\\)?\nWhat is \\(\\text{Var}(X)\\)?\n\nWhy complete this problem? This problem will solidify your foundational understanding of probability density functions, which are a bread-and-butter building block of applied statistics."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics 131a: Statistical Methods for Data Science",
    "section": "",
    "text": "Ed\n\n  DataHub\n\n  Gradescope\n\n\nNo matching items\nConcept check form",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#announcements",
    "href": "index.html#announcements",
    "title": "Statistics 131a: Statistical Methods for Data Science",
    "section": "Announcements üì£",
    "text": "Announcements üì£\nComplete the follow-up anonymous course pulse check.\nLab 7, Part A is due Monday 10/28 at midnight.\n\nThere is no longer a Part B to Lab 7.\n\nHW4 is due Monday 11/4 at midnight.\nThe Friday 11/1 lecture is asynchronous.\n\nJosh will record the lecture at a different time and post the recording.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Statistics 131a: Statistical Methods for Data Science",
    "section": "Schedule üìÖ",
    "text": "Schedule üìÖ\n\n\n\n \n\n   Week 10\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Nov 1:\n           \n           \n               Lecture 18b\n               \n                 More on logistic regression\n               \n          \n           \n                \n                 \n                   \n                     Asynchronous recording to be posted\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Oct 31:\n           \n           \n               Section 18\n               \n                 Conceptual review of regression and HW4 Help\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Oct 30:\n           \n           \n               Lecture 18a\n               \n                 Logistic Regression\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Oct 29:\n           \n           \n               Section 17\n               \n                 Cross-validation\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Oct 28:\n           \n           \n               Lecture 17\n               \n                 Cross-validation\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 9\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Oct 25:\n           \n           \n               Lecture 16c\n               \n                 Interactions\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Oct 24:\n           \n           \n               Section 16\n               \n                 Wrap up Lab 7, Review polynomial terms + categorical covariates\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Oct 23:\n           \n           \n               Lecture 16b\n               \n                 Categorical covariates\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Oct 22:\n           \n           \n               Section 15\n               \n                 Fitting linear regression (OLS) models\n               \n          \n           \n                \n                 \n                   \n                     Lab 7, Part A (DataHub)\n                   \n                 \n                   \n                     Lab 7, Part A (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Oct 21:\n           \n           \n               Lecture 16a\n               \n                 Polynomial terms\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 8\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Oct 18:\n           \n           \n               Lecture 15\n               \n                 Closeness of fit\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Oct 17:\n           \n           \n               Section 14\n               \n                 More on multiple testing + HW3 Help\n               \n          \n           \n                \n                 \n                   \n                     Lab 6 (DataHub)\n                   \n                 \n                   \n                     Lab 6 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Oct 16:\n           \n           \n               Lecture 14\n               \n                 Uncertainty in regression and multiple regression\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Oct 15:\n           \n           \n               Section 13\n               \n                 Multiple testing via simulation\n               \n          \n           \n                \n                 \n                   \n                     Lab 6 (DataHub)\n                   \n                 \n                   \n                     Lab 6 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Oct 14:\n           \n           \n               Lecture 13\n               \n                 Correlation and simple linear regression\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 7\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Oct 11:\n           \n           \n               Lecture 12b\n               \n                 Power and experiment planning\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Oct 9:\n           \n           \n               Lecture MT1\n               \n                 Midterm 1 (in class)\n               \n          \n           \n                \n                 \n                   \n                     Seating map\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Oct 8:\n           \n           \n               Section 11\n               \n                 Midterm 1 Prep Section\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Oct 7:\n           \n           \n               Lecture MT1P\n               \n                 Midterm 1 Prep Lecture\n               \n          \n           \n                \n                 \n                   \n                     Annotated worksheet/slides\n                   \n                 \n                   \n                     Worksheet/slides\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 6\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Oct 4:\n           \n           \n               Lecture 12a\n               \n                 Type I+II errors and multiple testing\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Oct 3:\n           \n           \n               Section 10\n               \n                 More on hypothesis testing\n               \n          \n           \n                \n                 \n                   \n                     Lab 5 (DataHub)\n                   \n                 \n                   \n                     Lab 5 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Oct 2:\n           \n           \n               Lecture 11b\n               \n                 More on hypothesis testing\n               \n          \n           \n                \n                 \n                   \n                     Slides (Updated)\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Oct 1:\n           \n           \n               Section 9\n               \n                 Intro to hypothesis testing\n               \n          \n           \n                \n                 \n                   \n                     Lab 5 (DataHub)\n                   \n                 \n                   \n                     Lab 5 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Sep 30:\n           \n           \n               Lecture 11a\n               \n                 Intro to hypothesis testing\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 5\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Sep 27:\n           \n           \n               Lecture 10b\n               \n                 More on confidence intervals\n               \n          \n           \n                \n                 \n                   \n                     Demo (DataHub)\n                   \n                 \n                   \n                     Demo (GitHub)\n                   \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Sep 26:\n           \n           \n               Section 8\n               \n                 Confidence intervals in R\n               \n          \n           \n                \n                 \n                   \n                     Lab 4, Part B (DataHub)\n                   \n                 \n                   \n                     Lab 4, Part B (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Sep 25:\n           \n           \n               Lecture 10a\n               \n                 Confidence intervals\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Sep 24:\n           \n           \n               Section 7\n               \n                 The bootstrap in R\n               \n          \n           \n                \n                 \n                   \n                     Lab 4, Part A (DataHub)\n                   \n                 \n                   \n                     Lab 4, Part A (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Sep 23:\n           \n           \n               Lecture 9\n               \n                 The bootstrap\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Demo (DataHub)\n                   \n                 \n                   \n                     Demo (GitHub)\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 4\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Sep 20:\n           \n           \n               Lecture 8b\n               \n                 More on sampling distributions\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Sep 19:\n           \n           \n               Section 6\n               \n                 Sampling distributions\n               \n          \n           \n                \n                 \n                   \n                     Lab 3 (DataHub)\n                   \n                 \n                   \n                     Lab 3 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Sep 18:\n           \n           \n               Lecture 8a\n               \n                 Sampling distributions\n               \n          \n           \n                \n                 \n                   \n                     Demo (DataHub)\n                   \n                 \n                   \n                     Demo (GitHub)\n                   \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Sep 17:\n           \n           \n               Section 5\n               \n                 Wrap up probability exercise and Lab 2\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Sep 16:\n           \n           \n               Lecture 7\n               \n                 Parallel universes\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 3\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Sep 13:\n           \n           \n               Lecture 6b\n               \n                 More parables and perplexing problems pertaining to probability\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Sep 12:\n           \n           \n               Section 4\n               \n                 Conceptual review of probability\n               \n          \n           \n                \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Sep 11:\n           \n           \n               Lecture 6a\n               \n                 Parables and perplexing problems pertaining to probability\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Sep 10:\n           \n           \n               Section 3\n               \n                 Working with distributions in R\n               \n          \n           \n                \n                 \n                   \n                     Lab 2 (DataHub)\n                   \n                 \n                   \n                     Lab 2 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Sep 9:\n           \n           \n               Lecture 5\n               \n                 Data from Distributions\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Annotated slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 2\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Sep 6:\n           \n           \n               Lecture 4\n               \n                 Distributions of Data\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Thu Sep 5:\n           \n           \n               Section 2\n               \n                 Data munging and plotting with stop-and-frisk\n               \n          \n           \n                \n                 \n                   \n                     Lab 1 (DataHub)\n                   \n                 \n                   \n                     Lab 1 (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Sep 4:\n           \n           \n               Lecture 3\n               \n                 Boxplots and Histograms\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lecture code (DataHub)\n                   \n                 \n                   \n                     Lecture code (GitHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Tue Sep 3:\n           \n           \n               Section 1\n               \n                 Data munging and plotting with stop-and-frisk\n               \n          \n           \n                \n                 \n                   \n                     Lab 1 (DataHub)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Mon Sep 2:\n           \n           \n               Holiday  (Labor Day)\n               \n                 \n               \n          \n           \n                \n           \n                \n           \n        \n   \n   \n   \n  \n\n   Week 1\n\n   \n   \n   \n   \n   \n   \n   \n\n        \n\n           \n           \n           Fri Aug 30:\n           \n           \n               Lecture 2\n               \n                 Principles of visualization\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n                   \n                     Lab 0 (HTML w/ DataHub Link)\n                   \n                 \n               \n           \n                \n           \n        \n   \n\n        \n\n           \n           \n           Wed Aug 28:\n           \n           \n               Lecture 1\n               \n                 Welcome!\n               \n          \n           \n                \n                 \n                   \n                     Slides\n                   \n                 \n                   \n                     Worksheet\n                   \n                 \n               \n           \n                \n           \n        \n   \n   \n   \n  \n\n\nNo matching items\n\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "Home / Schedule"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Students in Stat 131A are expected to have read the syllabus in its entirety by the second week of the course.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-details",
    "href": "syllabus.html#course-details",
    "title": "Syllabus",
    "section": "Course Details ü•ó",
    "text": "Course Details ü•ó\n\nDescription üîé\nStat 131A is a upper-division course that follows Data 8 or STAT 20. The course will teach a broad range of statistical methods that are used to solve data problems, including group comparisons, standard parametric statistical models, multivariate data visualization, multiple linear regression and classification, classification and regression trees, and random forests. Students will be introduced to the widely used R statistical language and they will obtain hands-on experience in implementing a range of statistical methods on numerous real world datasets.\nIn short, Stat 131A will provide you with a Swiss army knife of foundational statistical methods to use for data science projects!\n\n\nLectures üßë‚Äçüè´\nMWF 2-3pm @ Morgan 101\nLecture attendance is mandatory. See below for more details.\n\n\nLabs üß™\nLab 101: Tuesday and Thursday, 11am-12pm @ Evans 330\nLab 102: Tuesday and Thursday, 4-5pm @ Hearst Mining Bldg 310 (Hearst is next to Evans Hall)\nYou should only be signed up for one lab group.\nLab attendance is optional, but highly encouraged.\n\n\nOffice hours (OH) üóìÔ∏è\n\n\nJosh‚Äôs Office Hours:\n\nMWF 1:45pm + 3pm in lobby outside Morgan 101 (before and after lecture)\nT+Th 7-8:30pm @ Evans 334\n\nVan‚Äôs Office Hours:\n\nWednesdays 10am-12pm @ Evans 434\nWednesdays 4-5pm (group tutoring), TBD\nWednesdays 5-6pm (office hours), TBD\nFridays 9am-11am on Zoom\nFor security reasons, Zoom links for OH are posted on bcourses.\n\n15-minute coffee chats with Josh on the phone (experimental!):\n\nOne slot every weekday at 10am.\nDesigned for individual advising, not logistical concerns or coursework help.\nFor example, we can talk about career plans or life advice.\nPlease limit to no more than one chat per month.\nBook at this link\n\n\n\nWe may add or reschedule OH if needed.\n\nPlease create a private Ed post if you have conflicts with all of the scheduled OH.\n\nComing to office hours does not send a signal that you are behind or need extra help. In fact, the students who come to OH are often the most successful in the course.\n\nOH is a great opportunity to discuss not only topics directly related to the course, but also anything else that‚Äôs on your mind.\nWe also welcome questions about career trajectories and research opportunities at UC Berkeley and beyond.\nKeep in mind that you do not need to come to office hours with an agenda. Listening in is welcomed and encouraged!\nFinally, attending and participating in office hours is a great way to set yourself up for a terrific letter of recommendation. This is true for most courses!\nIf you don‚Äôt already, I highly recommend that you attend the instructors‚Äô office hours in other classes from time to time.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#study-groups",
    "href": "syllabus.html#study-groups",
    "title": "Syllabus",
    "section": "Study groups üë•",
    "text": "Study groups üë•\nWe encourage you to work together in groups to solidify your understanding of the course material.\nIf you would like assistance forming a study group, please complete the study group form by Monday, September 2nd at 11:59pm PT.\nOur goal is to form the study groups ASAP, so students can begin discussing the first homework assignment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#concurrent-enrollment-and-auditing",
    "href": "syllabus.html#concurrent-enrollment-and-auditing",
    "title": "Syllabus",
    "section": "Concurrent enrollment and auditing üëÇ",
    "text": "Concurrent enrollment and auditing üëÇ\nConcurrent enrollment students wishing to register for the class should fill out this Google Form to give me information about their previous coursework so we can assess whether they have satisfied the pre-requisites.\nUPDATE: Stat 131A will not be enrolling concurrent enrollment students in Fall 2024. But, concurrent enrollment students are welcome to audit the course.\nStudents who wish to audit the course can also fill out the top portion of this form to get their email added to bcourses as a guest. Only name and email is needed for auditors.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-platforms",
    "href": "syllabus.html#course-platforms",
    "title": "Syllabus",
    "section": "Course platforms üñ•Ô∏è",
    "text": "Course platforms üñ•Ô∏è\nbcourses will only be used for secure course material, like exam solutions, grades, and office hour Zoom links.\nAll other course materials will be posted on the public course homepage.\nAssignments should be submitted via Gradescope.\nAll course communication will take place via Ed.\nThe only acceptable large-language model (LLM) for use in Stat 131a is PingPong.\n\nUnless otherwise indicated, all other LLMs (e.g., ChatGPT) are prohibited and considered cheating in this course.\nEnrolled students will receive an invitation to PingPong via email shortly after the semester begins.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#grades",
    "href": "syllabus.html#grades",
    "title": "Syllabus",
    "section": "Grades üíØ",
    "text": "Grades üíØ\nGrades are calculated as follows:\n\nLecture attendance and participation: 10%\nLabs: 10%\nHomework: 20%\nFinal project: 15%\nMidterm 1 (during class): 10%\nMidterm 2 (during class): 15%\nFinal: 20%\n\nGrades will not be curved.\n\nIn other words, there is no limit to the proportion of students with an A, B, etc. You are incentivized to help each other learn and succeed.\nYou are guaranteed an A if you score 93% or higher, an A- if 90% or higher, a B+ if 87% or higher, a B if 83% or higher, and so on.\nA+ grades are awarded rarely, and only for truly exceptional performance.\nGrade cutoffs may be adjusted downward at the end of the semester, but this is not guaranteed.\n\nSee attendance policy below for an opportunity to earn up to two percentage points of extra credit.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#lecture-technology-policy",
    "href": "syllabus.html#lecture-technology-policy",
    "title": "Syllabus",
    "section": "Lecture technology policy ‚ùå üë©‚Äçüíª \\(~\\) ‚úÖüì±",
    "text": "Lecture technology policy ‚ùå üë©‚Äçüíª \\(~\\) ‚úÖüì±\nMost lectures will consist of an interactive problem-solving session, followed by a hands-on demo or coding session.\n\nLaptops and tablets with attached keyboards are not allowed during the problem-solving session, though you are permitted to use a tablet to take handwritten notes.\nIf you need to use technology for accessibility reasons, the previous bullet does not apply to you.\nLaptop use is permitted (and encouraged!) during the hands-on demo and coding sessions.\nPhones are allowed during lecture. It is preferable to use a phone to submit conceptual questions and neighbor discussion answers during lecture.\nThis article explains why we have the laptop policy. Long story short, laptop use can negatively impact the learning of nearby students (i.e., this policy does not punish you; the policy prevents you from punishing others).\nThe course staff reserves the right to reduce your lecture attendance grade for violating the technology policy.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#lecture-recordings",
    "href": "syllabus.html#lecture-recordings",
    "title": "Syllabus",
    "section": "Lecture recordings üé•",
    "text": "Lecture recordings üé•\nLectures will be recorded automatically.\n\nThe course staff cannot guarantee audio or video quality.\nLecture recordings are posted on bcourses.\n\nLabs and office hours are not recorded.\nThe homework assignments may occasionally ask you to watch additional recordings to supplement the lecture material (e.g., if we run out of time covering an essential topic).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#attendance-and-participation",
    "href": "syllabus.html#attendance-and-participation",
    "title": "Syllabus",
    "section": "Attendance and participation ‚úã",
    "text": "Attendance and participation ‚úã\nIn-person lecture attendance is mandatory.\n\nIt is critically important to practice learning in a live setting.\n\nDifficulty with paying attention in live meetings is a common hurdle for new grads.\n\nLecture attendance is a substantial component of your grade.\n\nLecture cannot be attended remotely.\nYou are allowed three unexcused lecture absences. Each additional absence will impact your lecture attendance grade.\n\nIf you cannot attend a lecture due to an extenuating circumstance, please complete the lecture attendance excusal form before the lecture starts.\n\nThis form can be completed months, weeks, or days in advance of lecture.\n\nAcceptable extenuating circumstances include:\n\nIllness. DO NOT come to class if you are sick! Even a sniffle!\nPersonal emergencies.\nImportant life events (e.g., weddings)\nPre-planned collegiate athletic events in which you are a participant.\nThis list is not exhaustive. If you think an absence should be excused, complete this form and explain your reasoning. We cannot guarantee that your absence will be excused, but we will be reasonable.\n\n\nConcept checks ‚úÖ\nWe will use in-class concept checks and neighbor discussions to track attendance.\n\nConcept checks are not graded.\nConcept checks are answered via this form. \nSubmitting a concept check outside of standard lecture time is considered cheating and an honor code violation. We will use your seat number and submission time to validate that your responses were entered during lecture time. We reserve the right to photograph the lecture hall to verify attendance.\n\n\n\nNeighbor discussions üó£Ô∏è\nIn addition to concept checks, there may be one or more neighbor discussions during each lecture.\n\nNeighbor discussion answers are submitted via this form.\nNeighbor discussion answers are not graded.\n\nTo encourage discussion among all classmates, we will award up to two percentage points of extra credit for having a variety of neighbors.\n\nThe students with the highest number of unique neighbors will receive the full two percentage points of extra credit.\nEveryone else will receive, at the minimum, a fraction of extra credit proportional to their number of unique neighbors.\nFor example, if you sit next to the same person all semester, you can receive full participation credit for neighbor discussions, but you will very little extra credit.\nThe extra credit policy will only take effect if at least one student has spoken to at least 20 unique neighbors over the course of the semester.\nAs above, submitting a neighbor discussion answer outside of standard lecture time is considered cheating and an honor code violation.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#homework",
    "href": "syllabus.html#homework",
    "title": "Syllabus",
    "section": "Homework üìù",
    "text": "Homework üìù\nThere are 6 homework assignments planned, though the exact number may change.\n\nHomework will be a combination of computational exercises and data analysis using the computer, as well as conceptual questions.\nHomework assignments are weighted equally.\n\nHW is generally due every other week.\n\nHomework assignments will be posted to the course website at least one week before the HW deadline.\nAll homework assignments will be submitted via Gradescope and are due by 11:59 pm of the due date.\n\nWe will not drop your lowest-scoring homework assignment.\n\nInstead, we will raise your lowest homework score to 80% of its maximum score, regardless of what you actually scored.\nWe will not change the grade of your lowest-scoring homework assignment if its score is above 80%.\n\nPoorly organized assignments will be docked points at the discretion of the grader.\n\nIt is critical to have empathy for the person who will be reviewing your work, whether a member of the course staff, another student providing feedback, or your future manager.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#late-hw",
    "href": "syllabus.html#late-hw",
    "title": "Syllabus",
    "section": "Late HW ‚è∞",
    "text": "Late HW ‚è∞\nYou are allotted five slip days for labs and homework assignments.\n\nEach slip day adds 24 hours to the deadline.\nSlip days cannot be used on the final project or exams.\nSlip days are intended to account for unexpected delays, like minor illness or homework overload.\nThere is no extra credit awarded for unused slip days.\nYou cannot use partial slip days.\n\nYou are allowed to use, at most, two slip days per assignment.\n\nIn other words, assignments will not be accepted more than 48 hours after the original due date.\nThis policy ensures that we can grade all assignments in a timely fashion.\n\nIf you plan to use slip days, do not contact the course staff.\n\nWe will automatically account for slip days when calculating grades.\n\nExtensions will only be granted if required by a Letter of Accommodation (LoA), or in extraordinary circumstances (e.g., medical emergencies).",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#labs-1",
    "href": "syllabus.html#labs-1",
    "title": "Syllabus",
    "section": "Labs üß™",
    "text": "Labs üß™\nDuring lab sessions, a GSI will review conceptual material and help you work through lab coding assignments.\n\nLab sections meet twice a week.\nThere are no lab sections the first week of classes.\n\nWe plan to have 12 lab assignments.\n\nEach assignment will teach you how to perform the analyses shown in class using R.\nLabs are intended to be finished or mostly finished during section.\nHW assignments may build on the exercises covered in lab.\n\nLab assignments are generally due on Mondays at 11:59 pm and should be submitted via Gradescope.\n\nLabs are graded on completion, not correctness.\n\nWhile there is no Week 1 lab, there is a self-paced Lab 0 for you to work through independently. This lab is not graded.\n\nBefore the first lab section on Tuesday of Week 2, work through Lab 0.\nYou do not have to turn in this lab, but we will assume that you have worked through this lab and understand the code.\nIf you have questions about this lab, please come to office hours or post on Ed.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#final-project",
    "href": "syllabus.html#final-project",
    "title": "Syllabus",
    "section": "Final project üìä",
    "text": "Final project üìä\nThe final project will be due on the last day of reading week, Friday December 13.\nMore details on the final project will be provided later in the semester.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#exams",
    "href": "syllabus.html#exams",
    "title": "Syllabus",
    "section": "Exams ‚åõ",
    "text": "Exams ‚åõ\nThe first midterm is scheduled for Wednesday October 9 and will take place during lecture in Morgan 101.\nThe second midterm is scheduled for Wednesday November 13 and will take place during lecture in Morgan 101.\nThe final exam will take place Thursday December 19, 3-6pm (scheduled by the registrar). Location TBD.\nAll exams are cumulative, with emphasis on more recent material.\n\nTo acknowledge maturation over the course of the semester, exams are increasingly weighted in your course grade.\nIf you do not perform well on the first midterm, you can still do very well in 131a!\n\nIf you cannot attend an exam due to an extenuating circumstance, please contact the course staff ASAP to determine whether your circumstance qualifies for a make-up exam.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#textbooks-and-resources",
    "href": "syllabus.html#textbooks-and-resources",
    "title": "Syllabus",
    "section": "Textbooks and resources üìñ",
    "text": "Textbooks and resources üìñ\nEverything you need to know for Stat 131a will be covered in lectures, labs, and assignments.\n\nIt is possible to do very well in Stat 131a without ever referring to an outside textbook or resource.\n\nHowever, most of the course material is covered by the online textbook developed specifically for 131A.\n\nYou can find the textbook here.\n\nThe StatQuest YouTube Channel is an excellent resource.\n\nStatQuest provides videos on many of the topics we will cover in class. The instructor is very entertaining!\n\nIf you would like some additional optional reading, you can try the following books.\n\nTheory Meets Data by Ani Adhikari. This is the online book for STAT 88 that covers introductory probability at the level of Stat 20.\nR for Data Science, by Garrett Grolemund and Hadley Wickham. This is a free online book that covers the tidyverse set of R packages.\nThe Statistical Sleuth: A Course in Methods of Data Analysis by Ramsey and Schafer\nIntroductory Statistics with R by Peter Dalgaard\n\nNone of these books covers all of the topics we will cover in 131A, nor do they necessarily have the same perspective and focus as this class.  But for those students wanting some additional structure or R assistance, these books may be helpful and should be at the right level for this class.\nStat 20 and Data 8 are similar courses, but each covers some subjects that the other does not. While we will cover these topics in class, you may find the following useful background if you are seeing them for the first time (more to follow):\n\nComputational and Inferential Thinking: The Foundations of Data Science, by Ani Adhikari and John DeNero ‚Äì chapters 11-13.\n\nThis is the online book used by Data 8. These chapters introduce hypothesis testing using only resampling ideas, ideas which are not necessarily covered in Stat 20.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#policy-on-large-language-models-llms",
    "href": "syllabus.html#policy-on-large-language-models-llms",
    "title": "Syllabus",
    "section": "Policy on Large Language Models (LLMs) üí¨",
    "text": "Policy on Large Language Models (LLMs) üí¨\nLLMs (e.g., ChatGPT) are becoming increasingly essential in the workplace.\n\nTo that end, the use of LLMs is not only permitted in this course, but encouraged.\nUse this course as an opportunity to learn where LLMs are most useful, and where they fall short.\n\nPotential uses of LLMs in Stat 131A:\n\nGenerating practice quiz questions\nExplaining course concepts\nHelping you code\n\nUnless otherwise indicated, you can only use the course-approved LLM PingPong for help on labs, homework, and the final project..\n\nFurthermore, if you use PingPong to help you, you must submit a PDF of the relevant PingPong conversation along with your assignment.\nYou are responsible for understanding every line of code that you submit in 131A. Exams may ask you to explain specific lines of code used in lab and HW solutions. So, don‚Äôt use LLMs to write code without taking time to understanding the code.\nOf course, LLMs cannot be used on exams.\n\nIt is often easy to spot default LLM text output.\n\nIf you copy and paste answers directly from PingPong, be warned that your grader may interpret your answer as lacking in effort and you may lose points on the assignment.\nTake the time to understand and paraphrase the information LLMs provide you.\n\n\n\n\n\nIf you find an especially interesting use case of an LLM for any component of the course, please share it with the course staff! We are excited to hear what you find.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#course-communication",
    "href": "syllabus.html#course-communication",
    "title": "Syllabus",
    "section": "Course communication üó£Ô∏è",
    "text": "Course communication üó£Ô∏è\nWe use the Ed platform to manage course questions and discussion, and to make announcements.\nIn general, do not email the course staff.\n\nException: You are welcome to email individual members of the course staff if you have a private concern that you do not want shared with the entire course staff.\n\nPlease post publicly when possible.\n\nPublic posts benefit many more students than private posts.\nWe may ask you to change your private post to a public post if the answer could be of use to other students.\nYou are always allowed to remain anonymous!\n\nIf you include code in your Ed post, please use the code editing fonts:\nStandard font is hard to read:\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ ‚úì ggplot2 3.3.2 ‚úì purrr 0.3.4 ‚úì tibble 3.0.3 ‚úì dplyr 1.0.2 ‚úì tidyr 1.1.2 ‚úì stringr 1.4.0 ‚úì readr 1.3.1 ‚úì forcats 0.5.0 ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ x dplyr::filter() masks stats::filter() x dplyr::lag() masks stats::lag()\n# here‚Äôs my plot code\nx &lt;- ggplot(df) +¬†geom_point(aes(x = year, y = count))\nCode font is easier to read:\n‚îÄ‚îÄ Attaching packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse 1.3.0 ‚îÄ‚îÄ\n‚úì ggplot2 3.3.2 ¬† ¬† ‚úì purrr ¬† 0.3.4\n‚úì tibble ¬†3.0.3 ¬† ¬† ‚úì dplyr ¬† 1.0.2\n‚úì tidyr ¬† 1.1.2 ¬† ¬† ‚úì stringr 1.4.0\n‚úì readr ¬† 1.3.1 ¬† ¬† ‚úì forcats 0.5.0\n‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\nx dplyr::filter() masks stats::filter()\nx dplyr::lag() ¬† ¬†masks stats::lag()\n\n# here's my plot code\nx &lt;- ggplot(df) + geom_point(aes(x = year, y = count))",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#computing-environment",
    "href": "syllabus.html#computing-environment",
    "title": "Syllabus",
    "section": "Computing environment üñ•Ô∏è",
    "text": "Computing environment üñ•Ô∏è\nThe official course materials use the R programming language.   \n\nAs in Data 8 and Stat 20, labs and assignments will be distributed via DataHub.\n\nYou do not need to know anything about R to take this course.\n\nWe will provide resources for you to learn everything you need to know.\n\nThe concepts taught in this course are language-agnostic.\n\nIn other words, everything you learn in this class can be readily implemented using a combination of other tools (e.g., Python, SQL, etc.).\nNote that LLMs are an excellent aid for translating your knowledge across different programming language and software.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#weekly-topics",
    "href": "syllabus.html#weekly-topics",
    "title": "Syllabus",
    "section": "Weekly topics ü•ó",
    "text": "Weekly topics ü•ó\nThe following is a rough and optimistic guideline for the material we will cover in the semester.\n\nThe actual topics may vary as the semester goes along.\nIt is likely that we will proceed more slowly than this schedule indicates.\nRelevant sections of the textbook are linked for each week, though you are only responsible for the material we cover in lecture, lab, or HW assignments.\n\nWeek 1. Principles of visualization.\nWeek 2. Boxplots and histograms. Discrete and continuous distributions. 2.1, 2.3.\nWeek 3. Probability. Bayes‚Äô theorem. Naive Bayes algorithm. 2.2.\nWeek 4. Sampling distributions. Bootstrapping. 2.4.\nWeek 5. Confidence intervals. Parametric hypothesis testing. 3.\nWeek 6. Non-parametric hypothesis testing. Type I and II errors. Power. Study design. Multiple testing. 3.\nWeek 7. Midterm 1 (Weeks 1-5). Linear regression. 4.1-4.3, 6\nWeek 8. More linear regression. Feature generation. Transformations. 6\nWeek 9. Cross-validation. Bias-variance tradeoff. Logistic regression. Classification error metrics. 7 7.5\nWeek 10. Buffer for Week 1-9 catch-up.\nWeek 11. Intro to non-parametric methods. Kernel density estimation (KDE). LOESS. 2.5. 4.4-4.5\nWeek 12. Midterm 2 (Weeks 1-10). Principle components analysis (PCA). Clustering. 5.4\nWeek 13. Decision trees. Random Forests. 8\nWeek 14. Buffer for Week 10-13 catch-up.\nWeek 15. Most likely, catch-up and review. If time permits, intro to causal inference.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#academic-honesty-policy",
    "href": "syllabus.html#academic-honesty-policy",
    "title": "Syllabus",
    "section": "Academic Honesty Policy üëç",
    "text": "Academic Honesty Policy üëç\nHomework and projects must be completed independently, with the following exceptions:\n\nYou may discuss specific issues/questions you have about the homework at a high level, but you must not sit down and do the assignment jointly.\nGiving advice about code or coding tips is also not cheating, but you can not directly share code with other classmates.\n\nFor exams, cheating includes, but is not limited to, using electronic materials in an exam beyond that allowed, copying off another person‚Äôs exam or quiz, allowing someone to copy off of your exam or quiz, and having someone take an exam or quiz for you.\nRequesting, obtaining, and/or using solutions from previous years or from the internet or other sources, if such happen to be available, is considered cheating.\nIn fairness to students who put in an honest effort, cheaters will be harshly treated.\n\nAny evidence of cheating will result in a score of zero (0) on the entire assignment or examination, and perhaps a failing grade in the class.\nWe will always report incidences of cheating to the Office of Student Conduct, which may administer additional punishment.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accommodations",
    "href": "syllabus.html#accommodations",
    "title": "Syllabus",
    "section": "Accommodations üíô",
    "text": "Accommodations üíô\nUC Berkeley is committed to creating a learning environment that meets the needs of its diverse student body including students with disabilities.\n\nIf you anticipate or experience any barriers to learning in this course, please feel welcome to discuss your concerns with Josh, whether after class, in office hours, via Ed, or via email.\n\nIf you already have a Letter of Accommodation, please open a private Ed post ASAP and attach your LoA.\n\nWe can accommodate you more easily if you provide this information early in the semester.\nWe cannot guarantee that last-minute requests for accommodation will be provided.\n\nIf you have a disability, or think you may have a disability, you can work with the Disabled Students‚Äô Program (DSP) to determine any accommodations you may need to have equal access in this course.\n\nThe Disabled Students‚Äô Program (DSP) is the campus office responsible for authorizing disability-related academic accommodations, in cooperation with the students themselves and their instructors.\nYou can find more information about the DSP application process here.\nJosh is available if you have any questions or concerns about your accommodations.\nIn the event of a disagreement, the proper procedure is for you to work with your DSP Specialist and your DSP Specialist to work with Josh toward a resolution.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "syllabus.html#accessible-ds-education-for-all",
    "href": "syllabus.html#accessible-ds-education-for-all",
    "title": "Syllabus",
    "section": "Accessible DS education for all ‚≠ê",
    "text": "Accessible DS education for all ‚≠ê\nIn support of our commitment to making Data Science education inviting, engaging, and respectful for people of diverse identities, backgrounds, experiences, and perspectives, I want to relay the following three items from the Data Science Undergraduate Studies (DSUS):\n\nDevice Lending options\nStudents can access device lending options through the Student Technology Equity Program (STEP) program.\n\n\nData Science Student Climate\nData Science Undergraduate Studies faculty and staff are committed to creating a community where every person feels respected, included, and supported. We recognize that incidents may happen, sometimes unintentionally, that run counter to this goal. There are many things we can do to try to improve the climate for students, but we need to understand where the challenges lie. If you experience a remark, or disrespectful treatment, or if you feel you are being ignored, excluded or marginalized in a course or program-related activity, please speak up. Consider talking to your instructor, but you are also welcome to contact Executive Director Christina Teller at cpteller@berkeley.edu or report an incident anonymously through this online form.\n\n\nCommunity Standards\nEd is a formal, academic space. Posts in this forum must relate to the course and be in alignment with Berkeley‚Äôs Principles of Community and the Berkeley Campus Code of Student Conduct. We expect all posts to demonstrate appropriate respect, consideration, and compassion for others. Please be friendly and thoughtful; our community draws from a wide spectrum of valuable experiences. Posts that violate these standards will be removed.",
    "crumbs": [
      "Syllabus"
    ]
  }
]